{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNniDeSdtE/pNOAyV4e9Wbt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzrossi/AMD-ComicsFaces/blob/main/ALL_MODELS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfMuoy28yOSP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "# Basic packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "# Image preprocessing\n",
        "import pathlib\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import cv2\n",
        "\n",
        "# Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import to_categorical, load_img, img_to_array\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import models, layers, callbacks, regularizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout, Activation\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.losses import binary_crossentropy\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "tfk = tf.keras\n",
        "tf.keras.backend.set_floatx(\"float64\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dir = '/content/drive/MyDrive/ComicsFaces'\n",
        "     \n",
        "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
        "\n",
        "X = pickle.load(open('/content/drive/MyDrive/ComicsFaces/Pickles/X.pickle','rb'))\n",
        "y = pickle.load(open('/content/drive/MyDrive/ComicsFaces/Pickles/y.pickle','rb'))\n",
        "\n",
        "pics_classes = ['comics','faces']\n",
        "\n",
        "images_to_plot = 6\n",
        "     \n",
        "\n",
        "f, ax = plt.subplots(1, images_to_plot)\n",
        "f.set_size_inches(30, 20)\n",
        "\n",
        "gray_channel = 0\n",
        "\n",
        "for i in range(images_to_plot):\n",
        "  gray_image = X[i][:, :, gray_channel]\n",
        "  ax[i].imshow(gray_image, cmap = \"gray\")\n",
        "  numeric_label = y[i]\n",
        "  ax[i].set_title(pics_classes[numeric_label])\n",
        "     \n",
        "\n",
        "\n",
        "number_of_classes = len(pics_classes)\n",
        "     \n",
        "\n",
        "x_size, img_dim = X.shape[0], X.shape[1]\n",
        "\n",
        "# rescale in [0,1]\n",
        "X = tf.cast(X, tf.float32) / 255.0\n",
        "\n",
        "# one hot encoding\n",
        "depth = 1\n",
        "y = tf.reshape(tf.one_hot(y, depth), shape = [x_size, depth])\n",
        "     \n",
        "\n",
        "# Train test splitting\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2)\n",
        "     \n",
        "\n",
        "# Hyperparameters\n",
        "epoch = 25 # n of epochs\n",
        "batch = 64 # batch size\n",
        "\n",
        "# Defining the loss\n",
        "loss = keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# Defining the optimizer(s)\n",
        "op_1 = Adam()\n",
        "#op_2 = SGD(learning_rate=0.01, momentum=0.9, decay=0.01/25)\n",
        "     \n",
        "\n",
        "# Defining plots\n",
        "legend_size = 14\n",
        "\n",
        "def performance_plot(history):\n",
        "    plt.figure(figsize=(20,8))\n",
        "\n",
        "    # Loss plots\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss', size = 12)\n",
        "    plt.xlabel('epoch', size = 12)\n",
        "    plt.legend(['train','test'], fontsize = legend_size)\n",
        "\n",
        "    # Accuracy plots\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['binary_accuracy'])\n",
        "    plt.plot(history.history['val_binary_accuracy'])\n",
        "    plt.ylabel('accuracy', size = 12)\n",
        "    plt.xlabel('epoch', size = 12)\n",
        "    plt.legend(['train','val'], fontsize = legend_size)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BASE ARCHITECTURE"
      ],
      "metadata": {
        "id": "gr2h52nqysDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "faVy3H9qyxII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, use_bias=False, activation='relu'),\n",
        "        layers.Dense(1, activation = 'sigmoid')\n",
        "        ])\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "ECHtXrESypHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model1, 'model.png')"
      ],
      "metadata": {
        "id": "nOIqUx_Sy2su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model1.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model1.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_1 = model1.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_1)"
      ],
      "metadata": {
        "id": "z6cMb33Yy5Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "Pp88pyCsy_eU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "FtT07b4FzAoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model2.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model2.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_2 = model2.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_2)"
      ],
      "metadata": {
        "id": "Suc7B3gQy7hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3"
      ],
      "metadata": {
        "id": "Sv4oHDTCzFVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "lzkHwHj7zDC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model3.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model3.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_3 = model3.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_3)"
      ],
      "metadata": {
        "id": "8hrzhWvhzLWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADDING DROPOUT LAYERS"
      ],
      "metadata": {
        "id": "ApgVfiId7hX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1"
      ],
      "metadata": {
        "id": "AGI7IPGb8BCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, use_bias=False, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation = 'sigmoid')\n",
        "        ])\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "LPoosUj470wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model1, 'model.png')"
      ],
      "metadata": {
        "id": "0vmYv8vd76ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model1.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model1.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_1 = model1.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_1)"
      ],
      "metadata": {
        "id": "P0eIQGZH761r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "0deFX2TC8Fon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "Jm1w90GZ8KMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model2.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model2.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_2 = model2.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_2)"
      ],
      "metadata": {
        "id": "4lCAGtCm8O3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "pYTsZhFU8Gwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "ZVlHysHm8LjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model3.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model3.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_3 = model3.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_3)"
      ],
      "metadata": {
        "id": "Yueagq3U8PPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADDING BATCH NORMALIZATION LAYERS"
      ],
      "metadata": {
        "id": "tIQIGjo67r3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "3cm2gQMg8aW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, use_bias=False, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation = 'sigmoid')\n",
        "        ])\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "oqYS903d8g75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model1, 'model.png')"
      ],
      "metadata": {
        "id": "8rZsQXJ08kcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model1.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model1.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_1 = model1.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_1)"
      ],
      "metadata": {
        "id": "Re-YBl1O8k3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "R82vz-H18anQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "wedgBFhP8nJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model2.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model2.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_2 = model2.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_2)"
      ],
      "metadata": {
        "id": "h10QYppJ8qMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "0etDDynN8ass"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "0Vj6RyuZ71NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model3.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model3.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_3 = model3.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_3)"
      ],
      "metadata": {
        "id": "ozeekXuC8vid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ADDING ADDITIONAL DENSE LAYER"
      ],
      "metadata": {
        "id": "r2qHVtl97wyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "iotOMDNj8ygp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, use_bias=False, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Dense(128, use_bias=False, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation = 'sigmoid')\n",
        "        ])\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "vqIPFA1Z83uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model1, 'model.png')"
      ],
      "metadata": {
        "id": "VvZxOUPj8_MB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model1.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model1.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_1 = model1.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_1)"
      ],
      "metadata": {
        "id": "1PPZuxju8_Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "OomGeKen8yjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(128, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "S8NZ5RIl84Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model2.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model2.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_2 = model2.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_2)"
      ],
      "metadata": {
        "id": "xirEiCWE9Gds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "0x7qcflB8ymM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(128, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "model3.summary()"
      ],
      "metadata": {
        "id": "LAKi1Yjp7cGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model3.compile(optimizer = op_1, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = model3.fit(X_train, y_train, epochs = epoch, batch_size = batch, verbose = 1, validation_split = 0.2)\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result_3 = model3.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result_3)"
      ],
      "metadata": {
        "id": "q461AreN9KSV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}